{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2ce3b0-18c5-4c67-a28c-bd99de1dd16e",
   "metadata": {},
   "source": [
    "## SUMMARY: Will correct the h5 prediction files for all of the single instance videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1048a-e7ed-45c6-aaea-6bca2e60ef17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# get single vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ed4884-4655-4306-afa0-500f36b8c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils import find_node_velocity, get_stats, fill_missing, graph_vels, nan_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09fb2ae-d5cd-4da1-a15e-f832003d87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultdir = '/gpfs/radev/pi/saxena/aj764'\n",
    "rootdir = f'{defaultdir}/PairedTestingSessions/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609ddee-7747-4de5-b018-0d7ceb2fbe13",
   "metadata": {},
   "source": [
    "Compiles a list of all of the sessions in PairedTestingSessions that have a Videos folder in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ec5448-a2b1-4cee-8119-32a5cb2e8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_subdirs = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    if subdir.endswith(\"Videos\"):\n",
    "        vid_subdirs.append(subdir)\n",
    "vid_subdirs = sorted(vid_subdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e4752a-8577-4a54-bf0c-1d591811c85e",
   "metadata": {},
   "source": [
    "Seperates all of the videos into single instance videos and multi instance videos (and takes out videos from before April)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d854de-5c8c-44a2-b29e-4a65a951c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_vids = {}\n",
    "multi_vids = {}\n",
    "for vids in vid_subdirs:\n",
    "    files = os.listdir(vids)\n",
    "    cut_vids = vids[28:]\n",
    "    single_vids[cut_vids] = []\n",
    "    multi_vids[cut_vids] = []\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4') and int(file[:2]) >= 4:\n",
    "            KL_count = file.count('KL')\n",
    "            EB_count = file.count('EB')\n",
    "            HF_count = file.count('HF')\n",
    "            if KL_count + EB_count + HF_count == 2:\n",
    "                multi_vids[cut_vids].append(file)\n",
    "            else:\n",
    "                single_vids[cut_vids].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0724851-ac2e-4bee-ab64-947a011e2389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1106 single instance videos\n"
     ]
    }
   ],
   "source": [
    "single_len_tot = 0\n",
    "for key, value in single_vids.items():\n",
    "    single_len_tot += len(value)\n",
    "print(f'There are {single_len_tot} single instance videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94eaa2b8-b375-42cb-9f29-f4fdf90a9023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 905 multi instance videos\n"
     ]
    }
   ],
   "source": [
    "multi_len_tot = 0\n",
    "for key, value in multi_vids.items():\n",
    "    multi_len_tot += len(value)\n",
    "print(f'There are {multi_len_tot} multi instance videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc049b-7415-410a-a2c3-2ba05dc8dc48",
   "metadata": {},
   "source": [
    "Fills in the NaN values for all of the single instance files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b54ea6-405c-4b20-9abc-a2c0601f4342",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# fills in missing vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea19671a-3ff7-432a-9af4-979bef73b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b796c8-4dfc-4d03-b2e2-317e79ac11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "total_intial_nan = 0\n",
    "total_after_out_nan = 0\n",
    "total_final_nan = 0\n",
    "\n",
    "for i, session in enumerate(single_vids.keys()): \n",
    "    video_list = single_vids[session]\n",
    "    analysis_path = defaultdir + '/' + session[:-6] + 'Tracking/h5/'\n",
    "    \n",
    "    for video in video_list:\n",
    "        # open analysis file\n",
    "        analysis_file = analysis_path + video[:-3] + 'predictions.h5'\n",
    "        with h5py.File(analysis_file,'r+') as f:\n",
    "            locations = f[\"tracks\"][:].T \n",
    "\n",
    "            # find nan values\n",
    "            intial = nan_vals(locations)\n",
    "\n",
    "            # just to check you haven't already done this vid or it isn't empty\n",
    "            if intial != 0:\n",
    "                # take out positional outliers\n",
    "                all_vels = {}\n",
    "                for node in range(locations.shape[1]):\n",
    "                    # find the velocities\n",
    "                    all_vels[node] = find_node_velocity(locations[:, node, :])\n",
    "                \n",
    "                    # get values need to find outliers\n",
    "                    mean, std, low, high = get_stats(all_vels[node])\n",
    "                \n",
    "                    # if you want to check that these values looks good\n",
    "                    graph_vels(all_vels[node], CHECK)\n",
    "                \n",
    "                    # replace outliers in locations with nan\n",
    "                    nan_index = [i for i in range(len(all_vels[node])) if (all_vels[node][i] > high or all_vels[node][i] < low)]\n",
    "                    for index in nan_index:\n",
    "                        locations[index + 1, node, 0], locations[index + 1, node, 0] = np.nan, np.nan\n",
    "                \n",
    "                    # if you want to check that new locations look good\n",
    "                    test_vels = find_node_velocity(locations[:, node, :])\n",
    "                    graph_vels(test_vels, check=CHECK, old_low=low, old_high=high)\n",
    "    \n",
    "                # find nan values again\n",
    "                after_out = nan_vals(locations)\n",
    "    \n",
    "                # fill in missing locations\n",
    "                print(f'video name: {video}')\n",
    "                new_locations = fill_missing(locations)\n",
    "                f[\"tracks\"][:] = new_locations.T\n",
    "\n",
    "                # finds nan values for final time\n",
    "                after_fill = nan_vals(new_locations)\n",
    "                \n",
    "                total_intial_nan += intial\n",
    "                total_after_out_nan += after_out\n",
    "                total_final_nan += after_fill\n",
    "    \n",
    "                # if you want to check the nan/fill values for a each video\n",
    "                if True:\n",
    "                    # print(f'video name: {video}')\n",
    "                    print(f'intial nan: {round(intial, 2)} %, after out nan: {round(after_out, 2)} %, final nan: {round(after_fill, 2)} %')\n",
    "        \n",
    "print('totals:')\n",
    "print(f'intial nan: {round(total_intial_nan / single_len_tot, 2)} %, after out nan: {round(total_after_out_nan / single_len_tot, 2)} %, final nan: {round(total_final_nan / single_len_tot, 2)} %')\n",
    "print(f'time elapse: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbe955-5fc4-4895-aa47-0396c83e4932",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# check our work... (abt 18 vids that I WOULDN'T trust!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "483f3996-73f7-41b0-b4db-a6567c173f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is one of vids I couldn't do anything abt\n",
      "091924_Cam2_TrNum15_IS_KL005Y.mp4\n",
      "this is one of vids I couldn't do anything abt\n",
      "102124_Cam1_TrNum8_IS_HF004Y.mp4\n"
     ]
    }
   ],
   "source": [
    "file = open('single_corrections_output.txt','r')\n",
    "output = file.readlines()\n",
    "\n",
    "intial = []\n",
    "after_out = []\n",
    "after_fill = []\n",
    "vid_name = []\n",
    "\n",
    "stupid_flag = True\n",
    "for line in output:\n",
    "    if \"video name\" in line:\n",
    "        vid_name.append(line[12:-1])\n",
    "        stupid_flag = True\n",
    "    if \"could\" in line:\n",
    "        print(\"this is one of vids I couldn't do anything abt\")\n",
    "        print(vid_name[-1])\n",
    "        vid_name.pop()\n",
    "        stupid_flag = False\n",
    "\n",
    "    if \"intial\" in line and stupid_flag:\n",
    "        parsed = line.split('%')\n",
    "        \n",
    "        init_temp = float(parsed[0][12:])\n",
    "        out_temp = float(parsed[1][16:])\n",
    "        fill_temp = float(parsed[2][12:])\n",
    "        intial.append(init_temp)\n",
    "        after_out.append(out_temp)\n",
    "        after_fill.append(fill_temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a24b879f-25ef-4897-8191-9b2d59d4e261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average over all videos:\n",
      "intial nan: 4.64 %, after out nan: 5.5 %, final nan: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"average over all videos:\")\n",
    "print(f'intial nan: {round(np.mean(intial), 2)} %, after out nan: {round(np.mean(after_out), 2)} %, final nan: {round(np.mean(after_fill), 2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1020a799-1311-4d0d-a8e8-317afc659e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.17 101824_Cam1_TrNum2_IS_KL004Y.mp4\n",
      "21.69 101824_Cam1_TrNum1_IS_KL003B.mp4\n",
      "22.73 101824_Cam2_TrNum1_IS_KL006G.mp4\n",
      "54.21 102124_Cam1_TrNum2_IS_HF006G.mp4\n",
      "47.02 102124_Cam1_TrNum1_IS_HF003B.mp4\n",
      "54.67 102124_Cam1_TrNum3_IS_HF004Y.mp4\n",
      "36.01 102124_Cam2_TrNum1_IS_HF006G.mp4\n",
      "32.88 102124_Cam2_TrNum3_IS_HF008Y.mp4\n",
      "43.66 102124_Cam2_TrNum8_IS_HF008Y.mp4\n",
      "30.4 102124_Cam2_TrNum2_IS_HF001R.mp4\n",
      "29.07 102224_Cam2_TrNum3_IS_HF003B.mp4\n",
      "32.05 102224_Cam2_TrNum1_IS_HF004Y.mp4\n",
      "31.84 102224_Cam2_TrNum2_IS_HF001R.mp4\n",
      "51.08 102224_Cam1_TrNum2_IS_HF008Y.mp4\n",
      "50.73 102224_Cam1_TrNum1_IS_HF001R.mp4\n",
      "55.0 102224_Cam1_TrNum3_IS_HF006G.mp4\n"
     ]
    }
   ],
   "source": [
    "# so for some reason these predictions started out atrocious... YIKES, maybe wouldn't trust the correct files\n",
    "for i, init in enumerate(intial):\n",
    "    if init > 20:\n",
    "        print(init, vid_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cdbd21-1704-4a07-b26f-d151b9f842f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9182311-116c-47e9-98e3-6a1049e20dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
